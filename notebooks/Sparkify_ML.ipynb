{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Predicting User Churn in Digital Music Services"]},{"metadata":{},"cell_type":"markdown","source":["Notebook to document data exploration and development of ML algorithm to identify at risk customers in digital music services."]},{"metadata":{},"cell_type":"markdown","source":["### Data Definition\n","\n","From Exploratory Data Analysis (EDA): \n","#### Useful:\n","- *location*: location of user, seems to append each new state (location, state)\n","- *gender*: user gender (M/F/None)\n","\n","- *page*: what page the user is on during event (pages)\n","- *level*: subscription level check uniqueness (free or paid)\n","- *auth*: authenication (logged in/out)\n","- *length*: time spent on page, max 50 mins on NextSong (if song paused??)\n","\n","- *registration*: unknown (registration unixtime)\n","- *ts*: timestamp of event in ms (event unixtime)\n","\n","- *userId*: unique (userId val)\n","- *sessionId*: unique sessionId per user?\n","- *itemInSession*: lcounter for the number of items in a single session (item listened to in session)\n","\n","\n","#### Not Useful:\n","- *firstName*: users first name (not important, remove)\n","- *lastName*: users lastname\n","- *artist*: song artist\n","- *song*: songname\n","- *userAgent*: device/browser (not important for us, remove)\n","- *method*: API PUT/GET http request (not important for us, remove)\n","- *status*: http status"]},{"metadata":{},"cell_type":"markdown","source":["### Imports"]},{"metadata":{},"cell_type":"code","source":["# imports\n","#import ibmos2spark\n","\n","# pyspark sql\n","from pyspark.sql import SparkSession, Window\n","from pyspark.sql.functions import from_unixtime, udf, col, when, isnan, desc\n","from pyspark.sql.functions import sum as Fsum\n","from pyspark.sql.types import IntegerType, StringType\n","from pyspark.sql import functions as F\n","\n","# pyspark ml\n","from pyspark.ml.feature import VectorAssembler, Normalizer, StringIndexer, OneHotEncoder\n","from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n","from pyspark.ml.pipeline import Pipeline\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","# python\n","import datetime\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style(\"darkgrid\")"],"execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### setup"]},{"metadata":{},"cell_type":"code","source":["# # config\n","# # @hidden_cell\n","# credentials = {\n","#     'endpoint': 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n","#     'service_id': 'iam-ServiceId-147e1161-7da9-41fe-ac00-c144730def00',\n","#     'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n","#     'api_key': 'kAtvjdC8VIYYUmU3gDaOYIK2fCvP3nkjYYlDiNuu4gw6'\n","# }\n","\n","# configuration_name = 'os_76774389dfa04fb5acbb1640b3e11704_configs'\n","# cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')"],"execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Build Spark session\n","spark = SparkSession.builder.appName(\"user_churn\").getOrCreate()\n","\n","# Read in data from IBM Cloud\n","# data_df = spark.read.json(cos.url('medium-sparkify-event-data.json', 'sparkify-donotdelete-pr-fnqu5byx41gcai'))\n","data_df = spark.read.parquet(\"../data/04_primary/medium-sparkify-event-data-features.parquet\")"],"execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Data Setup for ML Algorithm"]},{"metadata":{"tags":[]},"cell_type":"code","source":["data_df.printSchema()"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":"root\n |-- label: long (nullable = true)\n |-- userId: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- usStateAbbr: string (nullable = true)\n |-- avg_item_in_session: double (nullable = true)\n |-- avg_session_length: double (nullable = true)\n |-- num_good_recc: long (nullable = true)\n |-- num_bad_recc: long (nullable = true)\n |-- num_bad_sys: long (nullable = true)\n\n"}]},{"cell_type":"code","execution_count":24,"metadata":{"tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":"Row(label=1, userId='100012', gender='M', usStateAbbr='WI', avg_item_in_session=25.15568862275449, avg_session_length=242.23231660714296, num_good_recc=9, num_bad_recc=2, num_bad_sys=3)"},"metadata":{},"execution_count":24}],"source":["data_df.head()"]},{"metadata":{},"cell_type":"markdown","source":["## Create Features"]},{"metadata":{},"cell_type":"markdown","source":["### Onehot Encode Categorical Variables"]},{"metadata":{"tags":[]},"cell_type":"code","source":["## https://stackoverflow.com/questions/32277576/how-to-handle-categorical-features-with-spark-ml\n","\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n","cols = ['gender', 'usStateAbbr']\n","\n","indexers = [\n","    StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n","    for c in cols\n","]\n","\n","encoders = [\n","    OneHotEncoder(\n","        inputCol=indexer.getOutputCol(),\n","        outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) \n","    for indexer in indexers\n","]\n","\n","assembler = VectorAssembler(\n","    inputCols=[encoder.getOutputCol() for encoder in encoders],\n","    outputCol=\"features2\"\n",")\n","\n","pipeline = Pipeline(stages=indexers + encoders + [assembler])\n","data_df = pipeline.fit(data_df).transform(data_df)\n"],"execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Create Features Vector"]},{"metadata":{},"cell_type":"code","source":["# this vector is created in prep for ml\n","assembler = VectorAssembler(inputCols=[\"avg_item_in_session\",\n","                                       \"avg_session_length\",\n","                                       \"num_good_recc\",\n","                                       \"num_bad_recc\",\n","                                       \"num_bad_sys\",\n","                                       'gender_indexed',\n","                                       'usStateAbbr_indexed'],\n","                            outputCol=\"raw_features\",\n","                           handleInvalid=\"skip\")\n","data_df = assembler.transform(data_df)"],"execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# apply scaler\n","scaler = Normalizer(inputCol=\"raw_features\", outputCol=\"features\")\n","ml_df_prepped = scaler.transform(data_df)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["### Create custom evaluator"]},{"cell_type":"code","execution_count":49,"metadata":{"tags":[]},"outputs":[],"source":["def evaluate_model(results):\n","    \"\"\"Customer function to evaluate result.\n","    \"\"\"\n","    # Generic evaluation\n","    total_results = results.count()\n","    correct_pred = results.filter(results.label == results.prediction).count()\n","    incorrect_pred = results.filter(results.label != results.prediction).count()\n","    print('Total user events predicted correctly: {}'.format(correct_pred))\n","    print('Total user events predicted wrongly: {}'.format(incorrect_pred))\n","    print(\"Percentage predicted correct (%): {} \\n\".format((correct_pred/total_results)))\n","    \n","    # Correct churn predictions\n","    churn_correct = results.filter((results.label == 1) & (results.prediction == 1)).count()\n","    actual_churned_users = results.filter(results.label == 1).count()\n","    print('User churned and predicted to churn: {}'.format(churn_correct))\n","    print('User churned : {}'.format(actual_churned_users))\n","    print('Percent churned user events predicted correctly(%): {}\\n'.format((churn_correct/actual_churned_users)))\n","    \n","    # Incorrect churn predictions\n","    print('Number of events predicted to churn but didnt: {}'.format(results.filter((results.label == 0) & (results.label == 1)).count()))\n","    churn_incorrect = results.filter((results.label == 0) & (results.prediction == 1)).count()\n","    print('User did not churn and predicted to: {}'.format(churn_incorrect))\n","    print('Percent churned user events predicted correctly(%): {}\\n'.format(churn_incorrect/total_results))\n","    \n","    \n"]},{"metadata":{},"cell_type":"markdown","source":["# Train ML Model"]},{"metadata":{},"cell_type":"code","source":["# train test split for ML validation\n","train, test =  ml_df_prepped.randomSplit([0.6, 0.4], seed=42)  # more equal fit to combat overfitting\n","train.head(1)"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[Row(label=0, userId='100002', gender='F', usStateAbbr='CA', avg_item_in_session=31.25423728813559, avg_session_length=268.38730715328467, num_good_recc=11, num_bad_recc=2, num_bad_sys=3, gender_indexed=1.0, usStateAbbr_indexed=0.0, gender_indexed_encoded=SparseVector(1, {}), usStateAbbr_indexed_encoded=SparseVector(44, {0: 1.0}), features2=SparseVector(45, {1: 1.0}), raw_features=DenseVector([31.2542, 268.3873, 11.0, 2.0, 3.0, 1.0, 0.0]), features=DenseVector([0.1156, 0.9924, 0.0407, 0.0074, 0.0111, 0.0037, 0.0]))]"},"metadata":{},"execution_count":41}]},{"metadata":{"tags":[]},"cell_type":"code","source":["print(\"{} churned user events\".format(train.filter(train['label']==1).count()))\n","\n","print(\"{} non-churned user events\".format(train.filter(train['label']==0).count()))\n","\n","print(\"{} ratio of churned/non-churned user events\".format(train.filter(train['label']==1).count()/train.filter(train['label']==0).count()))"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":"62399 churned user events\n254906 non-churned user events\n0.24479219790824852 ratio of churned/non-churned user events\n"}]},{"metadata":{},"cell_type":"markdown","source":["## Baseline ML Model"]},{"metadata":{},"cell_type":"markdown","source":["baseline binary Logisitc Regression Model"]},{"metadata":{"tags":[]},"cell_type":"code","source":["results = LogisticRegression().fit(train).transform(test)\n","evaluate_model(results)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":"Total user events predicted correctly: 170373\nTotal user events predicted wrongly: 40327\nPercentage predicted correct (%): 0.8086046511627907 \n\nUser churned and predicted to churn: 3941\nUser churned : 41247\nPercent churned user events predicted correctly(%): 0.09554634276432225\n\nNumber of events predicted to churn but didnt: 0\nUser did not churn and predicted to: 3021\nPercent churned user events predicted correctly(%): 0.014337921214997627\n\n"}]},{"cell_type":"code","execution_count":51,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Total user events predicted correctly: 184519\nTotal user events predicted wrongly: 26181\nPercentage predicted correct (%): 0.8757427622211675 \n\nUser churned and predicted to churn: 15066\nUser churned : 41247\nPercent churned user events predicted correctly(%): 0.36526292821296097\n\nNumber of events predicted to churn but didnt: 0\nUser did not churn and predicted to: 0\nPercent churned user events predicted correctly(%): 0.0\n\n"}],"source":["# Fit and calculate predictions\n","results = RandomForestClassifier().fit(train).transform(test)\n","evaluate_model(results)"]},{"cell_type":"code","execution_count":52,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Total user events predicted correctly: 204272\nTotal user events predicted wrongly: 6428\nPercentage predicted correct (%): 0.9694921689606075 \n\nUser churned and predicted to churn: 34819\nUser churned : 41247\nPercent churned user events predicted correctly(%): 0.8441583630324629\n\nNumber of events predicted to churn but didnt: 0\nUser did not churn and predicted to: 0\nPercent churned user events predicted correctly(%): 0.0\n\n"}],"source":["# Fit and calculate predictions\n","results = GBTClassifier().fit(train).transform(test)\n","evaluate_model(results)"]},{"metadata":{},"cell_type":"markdown","source":["## Optimised ML Model"]},{"metadata":{},"cell_type":"code","source":["# pipeline, just running it on classifier no transformations\n","\n","gbt_model = GBTClassifier()\n","\n","pipeline = Pipeline(stages=[gbt_model])\n","\n","# set up param grid to iterate over\n","paramGrid = ParamGridBuilder() \\\n",".addGrid(gbt_model.maxDepth, [2, 4, 7]) \\\n",".addGrid(gbt_model.maxBins, [15, 40, 50]) \\\n",".addGrid(gbt_model.stepSize, [0.02, 0.2]) \\\n",".build()\n","\n","# set up crossvalidator to tune parameters and optimize\n","crossval = CrossValidator(estimator=pipeline,\n","                         estimatorParamMaps=paramGrid,\n","                         evaluator=MulticlassClassificationEvaluator(metricName='f1'),\n","                         numFolds=3)"],"execution_count":53,"outputs":[]},{"metadata":{},"cell_type":"code","source":["cvModel = crossval.fit(train)  # train model\n","results = cvModel.transform(test)  # apply model on test data"],"execution_count":54,"outputs":[]},{"cell_type":"code","execution_count":55,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Total user events predicted correctly: 210351\nTotal user events predicted wrongly: 349\nPercentage predicted correct (%): 0.998343616516374 \n\nUser churned and predicted to churn: 40898\nUser churned : 41247\nPercent churned user events predicted correctly(%): 0.991538778577836\n\nNumber of events predicted to churn but didnt: 0\nUser did not churn and predicted to: 0\nPercent churned user events predicted correctly(%): 0.0\n\n"}],"source":["evaluate_model(results)"]},{"metadata":{},"cell_type":"code","source":["cvModel.avgMetrics  # look at model scoring metrics"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[0.7735991524077506,\n 0.8307600265233073,\n 0.7902243411999164,\n 0.852009308215375,\n 0.8040890373611671,\n 0.8615093841220003,\n 0.8525021171831484,\n 0.9609473971428757,\n 0.8689646251652048,\n 0.9673013776843362,\n 0.8469729699292978,\n 0.9677221883693633,\n 0.9286818765501423,\n 0.9945904015326863,\n 0.9505490507083667,\n 0.9987713149098558,\n 0.946510784643793,\n 0.9989807612709432]"},"metadata":{},"execution_count":56}]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"PipelineModel_610c3d5c90b4"},"metadata":{},"execution_count":57}],"source":["cvModel.bestModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python_defaultSpec_1593346445254","display_name":"Python 3.7.6 64-bit","language":"python3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.7.6-final","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat":4,"nbformat_minor":1}